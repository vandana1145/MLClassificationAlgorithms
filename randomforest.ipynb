{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5cf534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # will be needed for saving preprocessing details\n",
    "import numpy as np # for data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "from sklearn.model_selection import train_test_split # will be used for data split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder # for preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier # for training the algorithm\n",
    "from sklearn.ensemble import ExtraTreesClassifier # for training the algorithm\n",
    "import joblib # for saving algorithm and preprocessing objects\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210cb3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('Data_without-columns (copy).csv')\n",
    "array = df.values\n",
    "print('Shape:', df.shape)\n",
    "# set input matrix and target column\n",
    "X = array[:, :-1]\n",
    "y = array[:, 6]\n",
    "# show first row of data\n",
    "print(df.head())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4612c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.25, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89fc3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking care of the missing data\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean', verbose = 0)\n",
    "imputer = imputer.fit(X[:, 1:6]) #upper bound is not included, but lower bound\n",
    "X[:, 1:6] = imputer.transform(X[:, 1:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b19d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the dependent variable\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y = labelencoder_Y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale data (between 0 and 1)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "rescaledX = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the class distribution\n",
    "target = df.values[:, -1]\n",
    "counter = Counter(target)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(target) * 100\n",
    "    print('Class=%s, Count=%s, Percentage=%.3f%%' % (k, v, per))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-summarize class distribution\n",
    "print(X.shape, y.shape,Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing SMOTE for the Imbalanced data in Multi-class classification\n",
    "smote=SMOTE(\"minority\")\n",
    "X,y=smote.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape, Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To balance another minority class\n",
    "smote=SMOTE(\"minority\")\n",
    "X,y=smote.fit_resample(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-summarize class distribution\n",
    "print(X.shape, y.shape,Counter(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - \n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['1'] = RandomForestClassifier(max_features=1)\n",
    "    models['2'] = RandomForestClassifier(max_features=2)\n",
    "    models['3'] = RandomForestClassifier(max_features=3)\n",
    "    models['4'] = RandomForestClassifier(max_features=4)\n",
    "    models['5'] = RandomForestClassifier(max_features=5)\n",
    "    models['6'] = RandomForestClassifier(max_features=6)\n",
    "    models['7'] = RandomForestClassifier(max_features=7)\n",
    "    models['8'] = RandomForestClassifier(max_features=8)\n",
    "    return models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a give model using cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def evaluate_model(model):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.xticks(rotation=45)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd01949c0c6eb6f836478006a9f6300681a60cd2c2e9487a6098efe3997da41e417",
   "display_name": "Python 3.8.5 64-bit ('anaconda3': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "1949c0c6eb6f836478006a9f6300681a60cd2c2e9487a6098efe3997da41e417"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}